# speech2face 

speech recognition based on facial images

The project consists of 2 major models:
1) Sound to FaceVector: converts soundwave into a facial recognition vector
2) FaceVector to Image: converts the above mentioned vector to an image

Current implementation consists of FaceVector to Image model

INSTRUCTIONS:

1) Upload notebook onto Google Drive
2) For VGG-16 backend, make sure you get at least 10GB of CUDA memory
3) For Facenet backend, any graphics card on Colab will suffice
4) Connect to Google Drive

TEST INSTRUCTIONS:

1) Run the cells containing imports, model classes and model loading
2) Upload test images
3) Run the cell for testing

TRAIN INSTRUCTIONS:

1) Download the required batches from Google Drive
2) Specify required learning rate and interations
3) Load pre-saved model
4) Select Run All from google colab


